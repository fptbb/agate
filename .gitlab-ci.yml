workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: "$CI_COMMIT_TAG"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: "$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS"
      when: never
    - if: "$CI_COMMIT_BRANCH"
    # Daily Builds
    - if: $CI_PIPELINE_SOURCE == "schedule"

stages:
  - build
  - cleanup

build-image:
  stage: build
  tags:
    - saas-linux-2xlarge-amd64
  image:
    name: ghcr.io/blue-build/cli
    entrypoint: [""]
  services:
    - docker:dind
  parallel:
    matrix:
      - RECIPE:
          - recipe.yml
  variables:
    # Setup a secure connection with docker-in-docker service
    # https://docs.gitlab.com/ee/ci/docker/using_docker_build.html
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: /certs
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: $DOCKER_TLS_CERTDIR/client
  before_script:
    # Pulls secure files into the build
    - curl --silent "https://gitlab.com/gitlab-org/incubation-engineering/mobile-devops/download-secure-files/-/raw/main/installer" | bash
    - export COSIGN_PRIVATE_KEY=$(cat .secure_files/cosign.key)
    - docker login $BB_REGISTRY -u $BB_USERNAME -p $BB_PASSWORD
  script:
    - sleep 5 # Wait a bit for the docker-in-docker service to start
    - echo "Pushing to $BB_REGISTRY/$BB_REGISTRY_NAMESPACE/agate"
    - bluebuild build --verbose --cache-layers --compression-format zstd --push ./recipes/$RECIPE

cleanup-old-tags:
  stage: cleanup
  image: python:3-alpine
  variables:
    IMAGE_NAME: agate
    MAX_AGE_DAYS: "7"
    MAX_KEEP: "5"
    DRY_RUN: "false"
  script:
    - pip install requests
    - |
      python3 -c '
      import os
      import sys
      import json
      import logging
      import requests
      from datetime import datetime, timezone
      from requests.auth import HTTPBasicAuth

      logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
      logger = logging.getLogger(__name__)

      class DockerV2Cleaner:
          def __init__(self):
              self.registry = "quay.io"
              namespace = os.environ.get("BB_REGISTRY_NAMESPACE")
              image = os.environ.get("IMAGE_NAME")
              self.repo = f"{namespace}/{image}"
              
              self.username = os.environ.get("BB_USERNAME")
              self.password = os.environ.get("BB_PASSWORD")
              self.dry_run = os.environ.get("DRY_RUN", "false").lower() == "true"
              
              if not all([namespace, image, self.username, self.password]):
                  logger.error("Missing variables.")
                  sys.exit(1)

              self.session = requests.Session()
              self.base_url = f"https://{self.registry}/v2"
              
              self.token = self.get_auth_token()
              self.session.headers.update({
                  "Authorization": f"Bearer {self.token}",
                  # Accept both standard Docker manifests and OCI artifacts (important for .sig)
                  "Accept": "application/vnd.docker.distribution.manifest.v2+json, application/vnd.oci.image.manifest.v1+json"
              })

          def get_auth_token(self):
              service = "quay.io"
              scope = f"repository:{self.repo}:pull,push"
              auth_url = f"https://{self.registry}/v2/auth?service={service}&scope={scope}"
              try:
                  resp = requests.get(auth_url, auth=HTTPBasicAuth(self.username, self.password))
                  if resp.status_code != 200:
                      logger.error(f"Auth Failed: {resp.text}")
                      sys.exit(1)
                  return resp.json().get("token")
              except Exception as e:
                  logger.error(f"Auth Error: {e}")
                  sys.exit(1)

          def get_all_tags(self):
              url = f"{self.base_url}/{self.repo}/tags/list"
              all_tags = []
              while url:
                  try:
                      resp = self.session.get(url)
                      if resp.status_code != 200: break
                      data = resp.json()
                      all_tags.extend(data.get("tags", []))
                      link = resp.headers.get("Link")
                      url = None
                      if link and "rel=\"next\"" in link:
                          url = link.split(";")[0].strip("<>")
                          if not url.startswith("http"): url = f"https://{self.registry}{url}"
                  except: break
              return all_tags

          def parse_date(self, date_str):
              try:
                  # Handle fractional seconds and Z
                  date_str = date_str.replace("Z", "+00:00")
                  # Truncate fractional seconds if python < 3.11 struggles (simple fix)
                  if "." in date_str and "+" in date_str:
                      main, tz = date_str.split("+")
                      main = main[:26] # Truncate to microseconds
                      date_str = f"{main}+{tz}"
                  return datetime.fromisoformat(date_str)
              except:
                  return None

          def get_tag_metadata(self, tag):
              """
              Robustly finds a date for the tag using 3 strategies.
              """
              try:
                  # 1. Fetch Manifest
                  man_resp = self.session.get(f"{self.base_url}/{self.repo}/manifests/{tag}")
                  if man_resp.status_code != 200: return None
                  
                  manifest = man_resp.json()
                  digest = man_resp.headers.get("Docker-Content-Digest")
                  dt = None

                  # STRATEGY A: Check OCI Annotations (Common in .sig/artifacts)
                  if "annotations" in manifest:
                      created = manifest["annotations"].get("org.opencontainers.image.created")
                      if created:
                          dt = self.parse_date(created)

                  # STRATEGY B: Check Config Blob (Standard Images)
                  if not dt and "config" in manifest:
                      config_digest = manifest["config"].get("digest")
                      if config_digest:
                          blob_resp = self.session.get(f"{self.base_url}/{self.repo}/blobs/{config_digest}")
                          if blob_resp.status_code == 200:
                              dt = self.parse_date(blob_resp.json().get("created"))

                  # STRATEGY C: Check V1 Compatibility History (Legacy/Older Images)
                  if not dt and "history" in manifest and len(manifest["history"]) > 0:
                      try:
                          v1_json = json.loads(manifest["history"][0]["v1Compatibility"])
                          dt = self.parse_date(v1_json.get("created"))
                      except: pass

                  if dt:
                      # Ensure timezone awareness
                      if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)
                      return {"name": tag, "date": dt, "digest": digest}
                  
                  logger.warning(f"Could not find date for tag: {tag} (skipping)")
                  return None

              except Exception as e:
                  logger.warning(f"Error processing {tag}: {e}")
                  return None

          def delete_tag(self, tag, digest):
              if self.dry_run:
                  logger.info(f"[DRY RUN] Delete {tag}")
                  return True
              
              resp = self.session.delete(f"{self.base_url}/{self.repo}/manifests/{digest}")
              if resp.status_code in [200, 202, 204]:
                  logger.info(f"Deleted {tag}")
                  return True
              logger.error(f"Failed to delete {tag}: {resp.status_code}")
              return False

          def run(self):
              max_age_days = int(os.environ.get("MAX_AGE_DAYS", 7))
              max_keep = int(os.environ.get("MAX_KEEP", 5))
              
              logger.info(f"Scanning {self.repo}...")
              tags = self.get_all_tags()
              logger.info(f"Found {len(tags)} tags. Fetching metadata...")

              tag_data = []
              protected_digests = set()

              for tag in tags:
                  meta = self.get_tag_metadata(tag)
                  if meta:
                      tag_data.append(meta)
                      if tag == "latest":
                          protected_digests.add(meta["digest"])

              # Sort by date (newest first)
              tag_data.sort(key=lambda x: x["date"], reverse=True)

              kept_count = 0
              for item in tag_data:
                  tag = item["name"]
                  digest = item["digest"]
                  age_days = (datetime.now(timezone.utc) - item["date"]).days

                  # 1. Protect Latest
                  if tag == "latest":
                      logger.info(f"Keeping {tag} (Protected)")
                      kept_count += 1
                      continue
                  
                  # 2. Protect Recent Count
                  if kept_count < max_keep:
                      logger.info(f"Keeping {tag} (Keep Limit)")
                      protected_digests.add(digest)
                      kept_count += 1
                      continue

                  # 3. Protect Shared Digests
                  if digest in protected_digests:
                      logger.info(f"Keeping {tag} (Shared Digest)")
                      continue

                  # 4. Check Age
                  if age_days > max_age_days:
                      self.delete_tag(tag, digest)
                  else:
                      logger.info(f"Keeping {tag} (Age: {age_days}d)")

      if __name__ == "__main__":
          cleaner = DockerV2Cleaner()
          cleaner.run()
      '