workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: "$CI_COMMIT_TAG"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: "$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS"
      when: never
    - if: "$CI_COMMIT_BRANCH"
    # Daily Builds
    - if: $CI_PIPELINE_SOURCE == "schedule"

stages:
  - build
  - cleanup

build-image:
  stage: build
  tags:
    - saas-linux-2xlarge-amd64
  image:
    name: ghcr.io/blue-build/cli
    entrypoint: [""]
  services:
    - docker:dind
  parallel:
    matrix:
      - RECIPE:
          - recipe.yml
  variables:
    # Setup a secure connection with docker-in-docker service
    # https://docs.gitlab.com/ee/ci/docker/using_docker_build.html
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: /certs
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: $DOCKER_TLS_CERTDIR/client
  before_script:
    # Pulls secure files into the build
    - curl --silent "https://gitlab.com/gitlab-org/incubation-engineering/mobile-devops/download-secure-files/-/raw/main/installer" | bash
    - export COSIGN_PRIVATE_KEY=$(cat .secure_files/cosign.key)
    - docker login $BB_REGISTRY -u $BB_USERNAME -p $BB_PASSWORD
  script:
    - sleep 5 # Wait a bit for the docker-in-docker service to start
    - echo "Pushing to $BB_REGISTRY/$BB_REGISTRY_NAMESPACE/agate"
    - bluebuild build --verbose --cache-layers --compression-format zstd --push ./recipes/$RECIPE

cleanup-old-tags:
  stage: cleanup
  image: python:3-alpine
  variables:
    IMAGE_NAME: agate
    MAX_AGE_DAYS: "7"
    MAX_KEEP: "5"
    DRY_RUN: "false"
  script:
    - pip install requests
    - |
      python3 -c '
      import os
      import sys
      import logging
      import requests
      import email.utils
      from requests.auth import HTTPBasicAuth
      from datetime import datetime, timedelta, timezone

      logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
      logger = logging.getLogger(__name__)

      class QuayImageCleaner:
          def __init__(self):
              self.registry = os.environ.get("BB_REGISTRY", "quay.io")
              self.namespace = os.environ.get("BB_REGISTRY_NAMESPACE")
              self.repository = os.environ.get("IMAGE_NAME")

              self.username = os.environ.get("BB_USERNAME")
              self.password = os.environ.get("BB_PASSWORD")

              self.dry_run = os.environ.get("DRY_RUN", "false").lower() == "true"

              if not all([self.namespace, self.repository, self.username, self.password]):
                  logger.error("Missing required variables: BB_REGISTRY_NAMESPACE, IMAGE_NAME, BB_USERNAME, or BB_PASSWORD.")
                  sys.exit(1)

              self.base_url = f"https://{self.registry}"
              self.session = requests.Session()

              self.session.auth = HTTPBasicAuth(self.username, self.password)
              self.session.headers.update({
                  "Content-Type": "application/json"
              })

          def get_image_tags(self):
              try:
                  url = f"{self.base_url}/api/v1/repository/{self.namespace}/{self.repository}/tag/"
                  params = {"limit": 100, "page": 1}
                  all_tags = []

                  while True:
                      response = self.session.get(url, params=params, timeout=30)
                      response.raise_for_status()
                      data = response.json()
                      tags = data.get("tags", [])

                      if not tags: break
                      all_tags.extend(tags)

                      if not data.get("has_additional", False): break
                      params["page"] += 1

                  logger.info(f"Found {len(all_tags)} tags in {self.namespace}/{self.repository}")
                  return all_tags
              except requests.exceptions.RequestException as e:
                  logger.error(f"Failed to get tags: {e}")
                  return []

          def delete_image_tag(self, tag):
              if self.dry_run:
                  logger.info(f"[DRY RUN] Would delete {tag}")
                  return True
              try:
                  url = f"{self.base_url}/api/v1/repository/{self.namespace}/{self.repository}/tag/{tag}"
                  response = self.session.delete(url, timeout=30)

                  if response.status_code == 403:
                      logger.error(f"403 Forbidden deleting {tag}. Check Robot Account Permissions for {self.username} on repo {self.namespace}/{self.repository}")
                      return False

                  response.raise_for_status()
                  logger.info(f"Deleted {tag}")
                  return True
              except requests.exceptions.RequestException as e:
                  logger.error(f"Failed to delete {tag}: {e}")
                  return False

          def parse_timestamp(self, timestamp_raw):
              """Robustly parse timestamp from int, string int, or RFC date string"""
              try:
                  if isinstance(timestamp_raw, (int, float)):
                      return datetime.fromtimestamp(timestamp_raw, tz=timezone.utc)

                  try:
                      return datetime.fromtimestamp(int(timestamp_raw), tz=timezone.utc)
                  except ValueError:
                      pass

                  # RFC 2822 parsing (handles "Wed, 14 Jan...")
                  dt = email.utils.parsedate_to_datetime(timestamp_raw)
                  if dt.tzinfo is None:
                      dt = dt.replace(tzinfo=timezone.utc)
                  return dt

              except Exception as e:
                  logger.warning(f"Failed to parse timestamp value: {timestamp_raw} ({e})")
                  return None

          def run(self):
              max_age_days = int(os.environ.get("MAX_AGE_DAYS", 7))
              max_keep = int(os.environ.get("MAX_KEEP", 5))

              logger.info(f"Starting cleanup: Max Age={max_age_days}d, Min Keep={max_keep}")

              tags = self.get_image_tags()
              if not tags: return

              for tag in tags:
                  tag["parsed_date"] = self.parse_timestamp(tag.get("last_modified"))

              # Sort tags by date (newest first)
              tags_sorted = sorted(
                  tags,
                  key=lambda t: t["parsed_date"] or datetime.min.replace(tzinfo=timezone.utc),
                  reverse=True
              )

              kept_count = 0
              for tag in tags_sorted:
                  tag_name = tag.get("name", "")
                  tag_date = tag.get("parsed_date")

                  if tag_name == "latest":
                      logger.info(f"Keeping {tag_name} (protected)")
                      kept_count += 1
                      continue

                  if kept_count < max_keep:
                      logger.info(f"Keeping {tag_name} (within max_keep limit)")
                      kept_count += 1
                      continue

                  if tag_date:
                      age_days = (datetime.now(timezone.utc) - tag_date).days
                      if age_days > max_age_days:
                          self.delete_image_tag(tag_name)
                          continue

                  logger.info(f"Keeping {tag_name} (not expired)")

      if __name__ == "__main__":
          cleaner = QuayImageCleaner()
          cleaner.run()
      '
