workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: "$CI_COMMIT_TAG"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: "$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS"
      when: never
    - if: "$CI_COMMIT_BRANCH"
    # Daily Builds
    - if: $CI_PIPELINE_SOURCE == "schedule"

stages:
  - build
  - cleanup

build-image:
  stage: build
  tags:
    - saas-linux-2xlarge-amd64
  image:
    name: ghcr.io/blue-build/cli
    entrypoint: [""]
  services:
    - docker:dind
  parallel:
    matrix:
      - RECIPE:
          - recipe.yml
  variables:
    # Setup a secure connection with docker-in-docker service
    # https://docs.gitlab.com/ee/ci/docker/using_docker_build.html
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: /certs
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: $DOCKER_TLS_CERTDIR/client
  before_script:
    # Pulls secure files into the build
    - curl --silent "https://gitlab.com/gitlab-org/incubation-engineering/mobile-devops/download-secure-files/-/raw/main/installer" | bash
    - export COSIGN_PRIVATE_KEY=$(cat .secure_files/cosign.key)
    - docker login $BB_REGISTRY -u $BB_USERNAME -p $BB_PASSWORD
  script:
    - sleep 5 # Wait a bit for the docker-in-docker service to start
    - echo "Pushing to $BB_REGISTRY/$BB_REGISTRY_NAMESPACE/agate"
    - bluebuild build --verbose --cache-layers --compression-format zstd --push ./recipes/$RECIPE

cleanup-old-tags:
  stage: cleanup
  image: python:3-alpine
  variables:
    IMAGE_NAME: agate
    MAX_AGE_DAYS: "7"
    MAX_KEEP: "5"
    DRY_RUN: "false"
  script:
    - pip install requests
    - |
      python3 -c '
      import os
      import sys
      import logging
      import requests
      from datetime import datetime, timezone
      from requests.auth import HTTPBasicAuth

      # Configure logging
      logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
      logger = logging.getLogger(__name__)

      class DockerV2Cleaner:
          def __init__(self):
              self.registry = "quay.io"
              # Ensure namespace/image format
              namespace = os.environ.get("BB_REGISTRY_NAMESPACE")
              image = os.environ.get("IMAGE_NAME")
              self.repo = f"{namespace}/{image}"
              
              self.username = os.environ.get("BB_USERNAME")
              self.password = os.environ.get("BB_PASSWORD")
              self.dry_run = os.environ.get("DRY_RUN", "false").lower() == "true"
              
              if not all([namespace, image, self.username, self.password]):
                  logger.error("Missing required variables.")
                  sys.exit(1)

              self.session = requests.Session()
              self.base_url = f"https://{self.registry}/v2"
              
              # 1. Authenticate with the Token Service
              self.token = self.get_auth_token()
              
              # 2. Configure Session with the Token
              self.session.headers.update({
                  "Authorization": f"Bearer {self.token}",
                  "Accept": "application/vnd.docker.distribution.manifest.v2+json"
              })

          def get_auth_token(self):
              """Exchanges User/Pass for a Bearer Token via the Auth Service"""
              service = "quay.io"
              # Requesting pull AND push scope (push often implies delete/write in V2)
              scope = f"repository:{self.repo}:pull,push"
              
              auth_url = f"https://{self.registry}/v2/auth?service={service}&scope={scope}"
              try:
                  resp = requests.get(auth_url, auth=HTTPBasicAuth(self.username, self.password))
                  if resp.status_code != 200:
                      logger.error(f"Auth Failed ({resp.status_code}): {resp.text}")
                      sys.exit(1)
                  return resp.json().get("token")
              except Exception as e:
                  logger.error(f"Failed to authenticate: {e}")
                  sys.exit(1)

          def get_all_tags(self):
              """Fetches all tags using pagination"""
              url = f"{self.base_url}/{self.repo}/tags/list"
              all_tags = []
              
              while url:
                  try:
                      resp = self.session.get(url)
                      if resp.status_code != 200:
                          logger.error(f"Failed to list tags: {resp.status_code}")
                          break
                      
                      data = resp.json()
                      all_tags.extend(data.get("tags", []))
                      
                      # Handle Link Header Pagination
                      link = resp.headers.get("Link")
                      url = None
                      if link and "rel=\"next\"" in link:
                          # Extract URL from <url>; rel="next"
                          url = link.split(";")[0].strip("<>")
                          # Ensure absolute URL if relative is returned
                          if not url.startswith("http"):
                              url = f"https://{self.registry}{url}"
                  except Exception as e:
                      logger.error(f"Error fetching tags: {e}")
                      break
              
              logger.info(f"Found {len(all_tags)} tags total.")
              return all_tags

          def get_tag_date_and_digest(self, tag):
              """
              Fetches the manifest to find the config blob, then the blob to find the creation date.
              This is heavy but necessary as V2 List doesn not provide dates.
              """
              try:
                  # Get Manifest
                  man_resp = self.session.get(f"{self.base_url}/{self.repo}/manifests/{tag}")
                  if man_resp.status_code != 200:
                      return None, None
                  
                  manifest = man_resp.json()
                  digest = man_resp.headers.get("Docker-Content-Digest")
                  
                  # Get Config Blob Digest
                  config_digest = manifest.get("config", {}).get("digest")
                  if not config_digest:
                      return None, None
                  
                  # Get Config Blob (contains the date)
                  blob_resp = self.session.get(f"{self.base_url}/{self.repo}/blobs/{config_digest}")
                  if blob_resp.status_code != 200:
                      return None, None
                  
                  created_str = blob_resp.json().get("created") # ISO 8601
                  # Parse Date
                  dt = datetime.fromisoformat(created_str.replace("Z", "+00:00"))
                  return dt, digest
              except Exception:
                  return None, None

          def delete_tag(self, tag, digest):
              if self.dry_run:
                  logger.info(f"[DRY RUN] Would delete {tag} (Digest: {digest})")
                  return True
              
              # V2 Deletion is by Digest, not Tag
              url = f"{self.base_url}/{self.repo}/manifests/{digest}"
              resp = self.session.delete(url)
              
              if resp.status_code in [202, 200, 204]:
                  logger.info(f"Deleted {tag}")
                  return True
              elif resp.status_code == 405:
                  logger.error(f"Delete Failed (405): Registry may have disabled Deletes or your password lacks permission.")
                  return False
              else:
                  logger.error(f"Delete Failed ({resp.status_code}) for {tag}")
                  return False

          def run(self):
              max_age_days = int(os.environ.get("MAX_AGE_DAYS", 7))
              max_keep = int(os.environ.get("MAX_KEEP", 5))
              
              tags = self.get_all_tags()
              if not tags: return

              logger.info("Fetching dates for all tags (this may take time)...")
              tag_data = []
              protected_digests = set()

              for tag in tags:
                  dt, digest = self.get_tag_date_and_digest(tag)
                  if dt and digest:
                      tag_data.append({"name": tag, "date": dt, "digest": digest})
                      if tag == "latest":
                          protected_digests.add(digest)

              # Sort by date descending (newest first)
              tag_data.sort(key=lambda x: x["date"], reverse=True)

              kept_count = 0
              for item in tag_data:
                  tag = item["name"]
                  digest = item["digest"]
                  
                  # Calculate Age
                  age_days = (datetime.now(timezone.utc) - item["date"]).days

                  # Protection 1: Latest
                  if tag == "latest":
                      logger.info(f"Keeping {tag} (Protected)")
                      kept_count += 1
                      continue
                  
                  # Protection 2: Max Keep Count
                  if kept_count < max_keep:
                      logger.info(f"Keeping {tag} (Keep Limit)")
                      protected_digests.add(digest)
                      kept_count += 1
                      continue

                  # Protection 3: Shared Digests (e.g. tag is same image as "latest")
                  if digest in protected_digests:
                      logger.info(f"Keeping {tag} (Shared Digest)")
                      continue

                  # Expiration Check
                  if age_days > max_age_days:
                      self.delete_tag(tag, digest)
                  else:
                      logger.info(f"Keeping {tag} (Age: {age_days}d)")

      if __name__ == "__main__":
          cleaner = DockerV2Cleaner()
          cleaner.run()
      '