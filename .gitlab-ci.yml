workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: "$CI_COMMIT_TAG"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: "$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS"
      when: never
    - if: "$CI_COMMIT_BRANCH"
    # Daily Builds
    - if: $CI_PIPELINE_SOURCE == "schedule"

stages:
  - build
  - publish
  - cleanup

build-image:
  stage: build
  tags:
    - saas-linux-2xlarge-amd64
  image:
    name: ghcr.io/blue-build/cli
    entrypoint: [""]
  services:
    - docker:dind
  parallel:
    matrix:
      - RECIPE:
          - recipe.yml
  variables:
    # Setup a secure connection with docker-in-docker service
    # https://docs.gitlab.com/ee/ci/docker/using_docker_build.html
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: /certs
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: $DOCKER_TLS_CERTDIR/client
  before_script:
    # Pulls secure files into the build
    - curl --silent "https://gitlab.com/gitlab-org/incubation-engineering/mobile-devops/download-secure-files/-/raw/main/installer" | bash
    - export COSIGN_PRIVATE_KEY=$(cat .secure_files/cosign.key)
    - docker login $BB_REGISTRY -u $BB_USERNAME -p $BB_PASSWORD
  script:
    - sleep 5 # Wait a bit for the docker-in-docker service to start
    - echo "Pushing to $BB_REGISTRY/$BB_REGISTRY_NAMESPACE/agate"
    - bluebuild build --verbose --cache-layers --compression-format zstd --push ./recipes/$RECIPE

publish-metadata:
  stage: publish
  image: alpine:latest
  variables:
    REGCTL_VERSION: v0.5.0
    DEST_REPO: "quay.io/fptbb/agate:artifacthub.io"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
  before_script:
    - apk add --no-cache curl
    - curl -L https://github.com/regclient/regclient/releases/download/${REGCTL_VERSION}/regctl-linux-amd64 > /usr/local/bin/regctl
    - chmod +x /usr/local/bin/regctl
    - echo "$BB_PASSWORD" | regctl registry login quay.io -u "$BB_USERNAME" --pass-stdin
  script:
    - |
      if [ ! -f "artifacthub-repo.yml" ]; then
        echo "Error: artifacthub-repo.yml not found in repository root."
        exit 1
      fi
    - |
      regctl artifact put \
        --format '{{ .Manifest.GetDescriptor.Digest }}' \
        --artifact-type application/vnd.cncf.artifacthub.config.v1+yaml \
        -f artifacthub-repo.yml \
        --file-media-type "application/vnd.cncf.artifacthub.repository-metadata.layer.v1.yaml" \
        $DEST_REPO

cleanup-old-tags:
  stage: cleanup
  image: python:3-alpine
  variables:
    IMAGE_NAME: agate
    MAX_AGE_DAYS: "7"
    MAX_KEEP: "5"
    DRY_RUN: "false"
  script:
    - pip install requests
    - |
      python3 -c '
      import os
      import sys
      import json
      import logging
      import requests
      from datetime import datetime, timezone
      from requests.auth import HTTPBasicAuth

      logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
      logger = logging.getLogger(__name__)

      class DockerV2Cleaner:
          def __init__(self):
              self.registry = "quay.io"
              namespace = os.environ.get("BB_REGISTRY_NAMESPACE")
              image = os.environ.get("IMAGE_NAME")
              self.repo = f"{namespace}/{image}"
              self.username = os.environ.get("BB_USERNAME")
              self.password = os.environ.get("BB_PASSWORD")
              self.dry_run = os.environ.get("DRY_RUN", "false").lower() == "true"
              
              if not all([namespace, image, self.username, self.password]):
                  logger.error("Missing variables.")
                  sys.exit(1)

              self.session = requests.Session()
              self.base_url = f"https://{self.registry}/v2"
              self.token = self.get_auth_token()
              self.session.headers.update({
                  "Authorization": f"Bearer {self.token}",
                  "Accept": "application/vnd.docker.distribution.manifest.v2+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.oci.image.index.v1+json"
              })

          def get_auth_token(self):
              scope = f"repository:{self.repo}:pull,push"
              auth_url = f"https://{self.registry}/v2/auth?service=quay.io&scope={scope}"
              try:
                  resp = requests.get(auth_url, auth=HTTPBasicAuth(self.username, self.password))
                  if resp.status_code != 200: sys.exit(1)
                  return resp.json().get("token")
              except: sys.exit(1)

          def get_all_tags(self):
              url = f"{self.base_url}/{self.repo}/tags/list"
              all_tags = []
              while url:
                  try:
                      resp = self.session.get(url)
                      if resp.status_code != 200: break
                      data = resp.json()
                      all_tags.extend(data.get("tags", []))
                      link = resp.headers.get("Link")
                      url = None
                      if link and "rel=\"next\"" in link:
                          url = link.split(";")[0].strip("<>")
                          if not url.startswith("http"): url = f"https://{self.registry}{url}"
                  except: break
              return all_tags

          def parse_date(self, date_str):
              try:
                  date_str = date_str.replace("Z", "+00:00")
                  if "." in date_str and "+" in date_str:
                      main, tz = date_str.split("+")
                      date_str = f"{main[:26]}+{tz}"
                  return datetime.fromisoformat(date_str)
              except: return None

          def fetch_manifest(self, digest_or_tag):
              try:
                  resp = self.session.get(f"{self.base_url}/{self.repo}/manifests/{digest_or_tag}")
                  if resp.status_code != 200: return None, None
                  return resp.json(), resp.headers.get("Docker-Content-Digest")
              except: return None, None

          def get_date_from_single_manifest(self, manifest):
              # Check OCI Annotations
              if "annotations" in manifest:
                  created = manifest["annotations"].get("org.opencontainers.image.created")
                  if created: return self.parse_date(created)
              
              # Check Config Blob
              if "config" in manifest:
                  cfg_digest = manifest["config"].get("digest")
                  if cfg_digest:
                      resp = self.session.get(f"{self.base_url}/{self.repo}/blobs/{cfg_digest}")
                      if resp.status_code == 200:
                          return self.parse_date(resp.json().get("created"))
                          
              # Check Legacy History
              if "history" in manifest and len(manifest["history"]) > 0:
                  try:
                      v1 = json.loads(manifest["history"][0]["v1Compatibility"])
                      return self.parse_date(v1.get("created"))
                  except: pass
              return None

          def get_tag_metadata(self, tag):
              # 1. Fetch Root Manifest (Could be Image OR Index/List)
              root_manifest, root_digest = self.fetch_manifest(tag)
              if not root_manifest: return None

              dt = None
              
              # Case A: It is a Manifest List / Index (Multi-Arch)
              if "manifests" in root_manifest:
                  # Grab the first sub-manifest to find the date
                  sub_digest = root_manifest["manifests"][0]["digest"]
                  sub_manifest, _ = self.fetch_manifest(sub_digest)
                  if sub_manifest:
                      dt = self.get_date_from_single_manifest(sub_manifest)
              # Case B: It is a Standard Image Manifest
              else:
                  dt = self.get_date_from_single_manifest(root_manifest)

              if dt:
                  if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)
                  return {"name": tag, "date": dt, "digest": root_digest}
              
              logger.warning(f"No date found for {tag} (Digest: {root_digest}). Skipping to be safe.")
              return None

          def delete_tag(self, tag, digest):
              if self.dry_run:
                  logger.info(f"[DRY RUN] Delete {tag}")
                  return True
              resp = self.session.delete(f"{self.base_url}/{self.repo}/manifests/{digest}")
              if resp.status_code in [200, 202, 204]:
                  logger.info(f"Deleted {tag}")
                  return True
              logger.error(f"Failed delete {tag}: {resp.status_code}")
              return False

          def get_cosign_sig_name(self, image_digest):
              clean_digest = image_digest.replace(":", "-")
              return f"{clean_digest}.sig"

          def run(self):
              max_age_days = int(os.environ.get("MAX_AGE_DAYS", 7))
              max_keep = int(os.environ.get("MAX_KEEP", 5))
              protected_tags = ["latest", "latest-cache"]

              logger.info(f"Scanning {self.repo}...")
              tags = self.get_all_tags()
              logger.info(f"Found {len(tags)} tags. Fetching metadata...")

              tag_data = []
              for tag in tags:
                  meta = self.get_tag_metadata(tag)
                  if meta: tag_data.append(meta)

              tag_data.sort(key=lambda x: x["date"], reverse=True)

              kept_digests = set()
              kept_sig_names = set()
              image_count = 0
              
              # Pass 1: Identify what to keep
              for item in tag_data:
                  name = item["name"]
                  digest = item["digest"]
                  
                  # Skip .sig files in the "Keep Count" logic
                  if name.endswith(".sig"): continue

                  if name in protected_tags:
                      kept_digests.add(digest)
                      kept_sig_names.add(self.get_cosign_sig_name(digest))
                      continue

                  if image_count < max_keep:
                      kept_digests.add(digest)
                      kept_sig_names.add(self.get_cosign_sig_name(digest))
                      image_count += 1

              # Pass 2: Cleanup
              for item in tag_data:
                  name = item["name"]
                  digest = item["digest"]
                  age_days = (datetime.now(timezone.utc) - item["date"]).days

                  if name in protected_tags:
                      logger.info(f"Keeping {name} (Protected)")
                      continue
                  
                  if digest in kept_digests and not name.endswith(".sig"):
                      logger.info(f"Keeping {name} (Active)")
                      continue

                  if name in kept_sig_names:
                      logger.info(f"Keeping {name} (Signature for Active Image)")
                      continue

                  if age_days > max_age_days:
                      self.delete_tag(name, digest)
                  else:
                      logger.info(f"Keeping {name} (Age: {age_days}d)")

      if __name__ == "__main__":
          cleaner = DockerV2Cleaner()
          cleaner.run()
      '